{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1af6ecd",
   "metadata": {},
   "source": [
    "This notebook performs a batch process for multiple files (a range of dates/times).  Each iteration includes the following tasks:\n",
    "\n",
    "    1. Obtain a NOAA hourly RAP Data from https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/\n",
    "    2. Read the obtained GRIB2 file using pygrib Library\n",
    "    3. Perform data transformation for the read file \n",
    "    4. Upload transformed data to an AWS S3 Bucket as a .csv file\n",
    "\n",
    "Note, this notebook was executed as an AWS SageMaker Notebook Instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10b48cf",
   "metadata": {},
   "source": [
    "### 1. Install/Call Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df503c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygrib\n",
      "  Downloading pygrib-2.1.3-cp36-cp36m-manylinux2014_x86_64.whl (15.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3 MB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyproj\n",
      "  Downloading pyproj-3.0.1-cp36-cp36m-manylinux2010_x86_64.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 62.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pygrib) (1.19.5)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyproj->pygrib) (2020.12.5)\n",
      "Installing collected packages: pyproj, pygrib\n",
      "Successfully installed pygrib-2.1.3 pyproj-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86147e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from shutil import copyfileobj\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f764ad32",
   "metadata": {},
   "source": [
    "### 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5db5a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns level ranges based on user specified minimum & maximum altitudes\n",
    "def convert_hPa (minimum_altitude, maximum_altitude):\n",
    "    altitude = []\n",
    "    hPa = []\n",
    "    min_alt = int(minimum_altitude)\n",
    "    max_alt = int(maximum_altitude)\n",
    "    range_summary = []\n",
    "    level_range = []\n",
    "    \n",
    "    # creating list of all hPa values from GRIB\n",
    "    for i in range(100, 1001, 25):\n",
    "        hPa.append(i)\n",
    "        \n",
    "    # converting hPa to pressure altitude feet using International Standard Atmosphere\n",
    "    for i in hPa:\n",
    "        alt = (1 - (i/1013.25)**0.190284) * 145366.45\n",
    "        FL = 'FL'+str(int(round(alt/100,-1)))\n",
    "        altitude.append([alt, FL, i])\n",
    "\n",
    "    for i in altitude:\n",
    "        if(i[0] >= min_alt and i[0] <= max_alt):\n",
    "            range_summary.append(i)\n",
    "            \n",
    "    for i in range_summary:\n",
    "        level_range.append(i[2])\n",
    "    return(level_range)\n",
    "\n",
    "# converts feet to pressure (hPa)\n",
    "def alt_to_hPa (alt):\n",
    "    a = (1/0.190284)\n",
    "    b =  alt/145366.45\n",
    "    P_hpa  = int(round(math.exp(math.log(1013.25) + (a*(math.log(1-b)))),0))\n",
    "    return P_hpa\n",
    "\n",
    "# Converts Relative Humidity Over Water to Realtive Humidity Over Ice\n",
    "a_ice = 21.8745484\n",
    "b_ice = 7.66\n",
    "a_water = 17.2693882\n",
    "b_water = 35.86\n",
    "\n",
    "def convertRH_water_to_RH_ice(row):\n",
    "    T = row['Temperature']\n",
    "    RH_water = row['RelativeHumidity']\n",
    "    RH_ice = RH_water * math.exp((a_water * (T - 273.16))/(T - b_water) - (a_ice * (T - 273.16))/(T - b_ice))\n",
    "    RH_ice = round(RH_ice,2)\n",
    "    return RH_ice\n",
    "\n",
    "# Determines ISSR\n",
    "def define_ISSR (row):\n",
    "    if row['Temperature'] < 233.15 and row['RH_ice'] > 100:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Converts pressure (hPa) to Flight Level\n",
    "def hPa_to_FL (row):\n",
    "    hPa = row['hPa']\n",
    "    alt = (1 - (hPa/1013.25)**0.190284) * 145366.45\n",
    "    #FL = 'FL'+str(int(round(alt/100,-1)))\n",
    "    FL = int(round(alt/100,-1))\n",
    "    return(FL) \n",
    "\n",
    "# Converts separate integer values of year, month, day, and hour to a single datetime value\n",
    "def convertdatetime(row):\n",
    "    yr = int(row['Year'])\n",
    "    mo = int(row['Month'])\n",
    "    dy = int(row['Day'])\n",
    "    hr = int(row['Hour'])\n",
    "    stamp = datetime(yr, mo, dy, hr)\n",
    "    return str(stamp)\n",
    "\n",
    "# Develop urls based on user-specified date/time range\n",
    "def get_RAP_urls(firstDT, lastDT):\n",
    "    url_begin = 'https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/'\n",
    "    if (firstDT >= lastDT):\n",
    "        lastDT = firstDT\n",
    "\n",
    "    dateTimes = pd.date_range(firstDT, lastDT, freq= 'H')\n",
    "    dateTimesSer = pd.Series([str(dateTime) for dateTime in dateTimes], name= 'temp')\n",
    "    dateTimesDF = pd.DataFrame({'yr':list(dateTimesSer.str.slice(0,4)), \n",
    "                                    'mo':list(dateTimesSer.str.slice(5,7)), \n",
    "                                    'day':list(dateTimesSer.str.slice(8,10)), \n",
    "                                    'hr':list(dateTimesSer.str.slice(11,13))})\n",
    "\n",
    "    dateTimesDF['yrmo'] = dateTimesDF['yr'] + dateTimesDF['mo']\n",
    "    dateTimesDF['yrmoday'] = dateTimesDF['yrmo'] + dateTimesDF['day']\n",
    "    dtDF = dateTimesDF.iloc[0:len(dateTimesDF)].copy()\n",
    "    siteNames = [url_begin + dtDF.iloc[i,4] + \"/\" + dtDF.iloc[i,5] + '/rap_252_' + dtDF.iloc[i,5] + '_' + dtDF.iloc[i,3] + '00_000.grb2' for i in range(len(dtDF))]\n",
    "    \n",
    "    return siteNames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d1e095",
   "metadata": {},
   "source": [
    "### 3. User Input for Date/Time Range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4e396b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_0000_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_0100_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_0200_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_0300_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_0400_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_0500_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_0600_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_0700_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_0800_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_0900_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_1000_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_1100_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_1200_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_1300_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_1400_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_1500_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_1600_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_1700_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_1800_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_1900_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_2000_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_2100_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_2200_000.grb2\n",
      "https://www.ncei.noaa.gov/data/rapid-refresh/access/rap-252-20km/analysis/202012/20201210/rap_252_20201210_2300_000.grb2\n"
     ]
    }
   ],
   "source": [
    "# User input\n",
    "beginDT = '2020-12-10 00:00:00' # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< User Input\n",
    "endDT =   '2020-12-10 23:00:00' # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< User Input\n",
    "\n",
    "urls = get_RAP_urls(beginDT, endDT)\n",
    "\n",
    "# Print urls that the GRIB2 files will be obtained\n",
    "for url in urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ec2838",
   "metadata": {},
   "source": [
    "### 4. Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ee7f164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_12_10_00.csv done at 2021-06-09 10:09:43.638962\n",
      "2020_12_10_01.csv done at 2021-06-09 10:11:40.914998\n",
      "2020_12_10_02.csv done at 2021-06-09 10:13:32.565984\n",
      "2020_12_10_03.csv done at 2021-06-09 10:15:26.182598\n",
      "2020_12_10_04.csv done at 2021-06-09 10:17:18.418933\n",
      "2020_12_10_05.csv done at 2021-06-09 10:19:10.424229\n",
      "2020_12_10_06.csv done at 2021-06-09 10:21:01.233906\n",
      "2020_12_10_07.csv done at 2021-06-09 10:22:52.438985\n",
      "2020_12_10_08.csv done at 2021-06-09 10:24:58.858835\n",
      "2020_12_10_09.csv done at 2021-06-09 10:26:54.482618\n",
      "2020_12_10_10.csv done at 2021-06-09 10:28:49.858871\n",
      "2020_12_10_11.csv done at 2021-06-09 10:30:41.831033\n",
      "2020_12_10_12.csv done at 2021-06-09 10:32:34.658219\n",
      "2020_12_10_13.csv done at 2021-06-09 10:34:28.513998\n",
      "2020_12_10_14.csv done at 2021-06-09 10:36:22.506017\n",
      "2020_12_10_15.csv done at 2021-06-09 10:38:14.735625\n",
      "2020_12_10_16.csv done at 2021-06-09 10:40:06.966493\n",
      "2020_12_10_17.csv done at 2021-06-09 10:41:59.251864\n",
      "2020_12_10_18.csv done at 2021-06-09 10:43:50.530916\n",
      "2020_12_10_19.csv done at 2021-06-09 10:45:42.951632\n",
      "2020_12_10_20.csv done at 2021-06-09 10:47:34.460592\n",
      "2020_12_10_21.csv done at 2021-06-09 10:49:26.206143\n",
      "2020_12_10_22.csv done at 2021-06-09 10:51:18.596348\n",
      "2020_12_10_23.csv done at 2021-06-09 10:53:10.416199\n"
     ]
    }
   ],
   "source": [
    "# Each iteration performs dowloading a GRIB2 file, reading the downloaded file, \n",
    "# extracting & transforming necessary data, and writing a .csv file to a user-specified AWS s3 bucket   \n",
    "for my_url in urls:\n",
    "    with urlopen(my_url) as in_stream, open('my_gribfile.grib2', 'wb') as out_file:\n",
    "        copyfileobj(in_stream, out_file)\n",
    "    grbs = pygrib.open('my_gribfile.grib2')\n",
    "    \n",
    "    temperature = {}\n",
    "    relative_humidity = {}\n",
    "    latitude = {}\n",
    "    longitude = {}\n",
    "    data = {}\n",
    "    ISSR = {}\n",
    "    latlon = {'lat_lon' : []}\n",
    "    lat = []\n",
    "    lon= []\n",
    "    count = 0\n",
    "    min_alt = int(19000)\n",
    "    max_alt = int(45000)\n",
    "\n",
    "    for grb in grbs:\n",
    "            if grb.level in convert_hPa(min_alt,max_alt):\n",
    "                if grb.parameterName == 'Temperature':\n",
    "                    temperature.update({grb.level : {grb.parameterName : np.round(np.array(grb.values),3).tolist()}})\n",
    "                    #temperature.update({grb.level : {grb.parameterName : numpy.round(numpy.array(grb.values),3), 'temp_validation' : validation()}})\n",
    "                if grb.parameterName == 'Relative humidity':\n",
    "                    relative_humidity.update({grb.level : {grb.parameterName : np.round(np.array(grb.values),2).tolist()}})\n",
    "                    #relative_humidity.update({grb.level : {grb.parameterName : numpy.round(numpy.array(grb.values),2), 'rh_validation' : validation()}})\n",
    "\n",
    "            lat,lon = grb.latlons()\n",
    "            lat = lat.T.tolist()\n",
    "            lon = lon.T.tolist()\n",
    "    # adding year, month, day, hour to data dictionary\n",
    "    #data = {'lat_lon' : [], 'data' : {grb.year : {grb.month : {grb.day : {grb.hour : {}}}}}} # including lat lon for each level\n",
    "    data = {'data' : {grb.year : {grb.month : {grb.day : {grb.hour : {}}}}}} # excluding lat lon for each level  \n",
    "    grbs.close()\n",
    "    \n",
    "    for year in data['data']:\n",
    "            #print('data year:',year,type(year))\n",
    "            for month in data['data'][year]:\n",
    "                #print('data month:', month,type(month))\n",
    "                for day in data['data'][year][month]:\n",
    "                    #print('data day:', day,type(day))\n",
    "                    for hour in data['data'][year][month][day]:\n",
    "                        #print('data hour:', hour,type(hour))\n",
    "                        data['data'][year][month][day][hour].update(temperature)\n",
    "                        for level in data['data'][year][month][day][hour]:\n",
    "                            #print('data level:', level,type(level))\n",
    "                            data['data'][year][month][day][hour][level].update(relative_humidity[level])\n",
    "\n",
    "    df = pd.DataFrame() \n",
    "\n",
    "        # append columns to an empty DataFrame \n",
    "    df['Year'] = [] \n",
    "    df['Month'] = [] \n",
    "    df['Day'] = [] \n",
    "    df['Hour'] = []\n",
    "    df['hPa'] = []\n",
    "    df['Nx'] = []\n",
    "    df['Ny'] = []\n",
    "    df['Lat'] = []\n",
    "    df['Lon'] = []\n",
    "    df['Temperature'] = []\n",
    "    df['RelativeHumidity'] = []\n",
    "    df['IsISSR'] = []\n",
    "\n",
    "    counter = 0\n",
    "    year_list = []\n",
    "    month_list = []\n",
    "    day_list = []\n",
    "    hour_list = []\n",
    "    level_list = []\n",
    "    Nx_list = []\n",
    "    Ny_list = []\n",
    "    Lat_List = []\n",
    "    Lon_List = []\n",
    "    Temp_List = []\n",
    "    RH_List = []\n",
    "\n",
    "\n",
    "    for levelIndex, level in enumerate(data['data'][year][month][day][hour]):\n",
    "        for variableindex, variable in enumerate(data['data'][year][month][day][hour][level]):\n",
    "            if(variable == \"Temperature\"):\n",
    "                for Ny_index, list_of_Ny_no_of_temperature_values in enumerate(data['data'][year][month][day][hour][level][variable]):\n",
    "                    for Nx_index,temperature_value in enumerate(list_of_Ny_no_of_temperature_values):\n",
    "                        year_list.append(year)\n",
    "                        month_list.append(month)\n",
    "                        day_list.append(day)\n",
    "                        hour_list.append(hour)\n",
    "                        level_list.append(level)\n",
    "                        Nx_list.append(Nx_index+1)\n",
    "                        Ny_list.append(Ny_index+1)\n",
    "                        Temp_List.append(temperature_value)\n",
    "                        Lat_List.append(lat[Nx_index][Ny_index])\n",
    "                        Lon_List.append(lon[Nx_index][Ny_index])\n",
    "\n",
    "            if(variable == \"Relative humidity\"):\n",
    "                for Ny_index, list_of_Ny_no_of_temperature_values in enumerate(data['data'][year][month][day][hour][level][variable]):\n",
    "                    for Nx_index,rh_value in enumerate(list_of_Ny_no_of_temperature_values):\n",
    "                        RH_List.append(rh_value)\n",
    "    df['Year'] = year_list \n",
    "    df['Month'] = month_list\n",
    "    df['Day'] = day_list\n",
    "    df['Hour'] = hour_list\n",
    "    df['hPa'] = level_list\n",
    "    df['Nx'] = Nx_list\n",
    "    df['Ny'] = Ny_list\n",
    "    df['Lat'] = Lat_List\n",
    "    df['Lon'] = Lon_List\n",
    "    df['Temperature'] = Temp_List\n",
    "    df['RelativeHumidity'] = RH_List\n",
    "    \n",
    "    df['RH_ice'] = df.apply(lambda row: convertRH_water_to_RH_ice (row), axis=1)\n",
    "    df['IsISSR'] = df.apply(lambda row: define_ISSR (row), axis=1)\n",
    "    df['FLevel'] = df.apply(lambda row: hPa_to_FL (row), axis=1)\n",
    "    df['dateTime'] = df.apply(lambda row: convertdatetime (row), axis=1)\n",
    "    final_df = df[['dateTime', 'hPa', 'FLevel','Nx', 'Ny', 'Lat', 'Lon','Temperature', 'RH_ice', 'IsISSR']]\n",
    "    \n",
    "    stampText = final_df.iloc[0]['dateTime']\n",
    "    outFileName = stampText[0:4] + \"_\" + stampText[5:7] + \"_\" + stampText[8:10] + \"_\" + stampText[11:13] + \".csv\"\n",
    "    \n",
    "#    final_df.to_csv('final.csv', index= False) # local temporary storage\n",
    "    \n",
    "#    s3 = boto3.resource('s3')\n",
    "#    s3.Bucket('partly-cloudy-XXXXXXXXXXXX').upload_file('final.csv', outFileName) # <<<<<<<<<<<<<<<<< User Input (s3 Bucket Name)\n",
    "#    print(outFileName + \" done at \" + str(datetime.now())) # print out completed files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab2a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
